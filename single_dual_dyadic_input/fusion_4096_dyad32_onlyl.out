  1) releases/2021b
job start at Thu Feb 29 15:13:28 CET 2024
2024-02-29 15:13:32.793793: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-29 15:13:32.794752: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.
2024-02-29 15:13:35.084285: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-29 15:13:35.084932: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2600000000 Hz
 
first y shape:  (112000, 8)
datagenerator definition successfull
start AI architecture definition
Model: "model"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input6 (InputLayer)          [(None, 2, 128, 1)]       0         
_________________________________________________________________
conv2d (Conv2D)              (None, 1, 121, 30)        510       
_________________________________________________________________
dropout (Dropout)            (None, 1, 121, 30)        0         
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 1, 118, 10)        1210      
_________________________________________________________________
dropout_1 (Dropout)          (None, 1, 118, 10)        0         
_________________________________________________________________
flatten (Flatten)            (None, 1180)              0         
_________________________________________________________________
dense1 (Dense)               (None, 128)               151168    
_________________________________________________________________
dense2 (Dense)               (None, 8)                 1032      
_________________________________________________________________
reshape (Reshape)            (None, 8)                 0         
=================================================================
Total params: 153,920
Trainable params: 153,920
Non-trainable params: 0
_________________________________________________________________
end of architecture
 
Training start
Epoch 1/100
2450/2450 - 779s - loss: 2.0816 - accuracy: 0.1272 - val_loss: 2.0792 - val_accuracy: 0.1277
2024-02-29 15:26:34.379567: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.

Epoch 00001: val_loss improved from inf to 2.07918, saving model to ./weights_folder/fusion_4096_dyad32_only
Epoch 2/100
2450/2450 - 29s - loss: 2.0795 - accuracy: 0.1282 - val_loss: 2.0789 - val_accuracy: 0.1267

Epoch 00002: val_loss improved from 2.07918 to 2.07887, saving model to ./weights_folder/fusion_4096_dyad32_only
Epoch 3/100
2450/2450 - 30s - loss: 2.0783 - accuracy: 0.1306 - val_loss: 2.0770 - val_accuracy: 0.1313

Epoch 00003: val_loss improved from 2.07887 to 2.07696, saving model to ./weights_folder/fusion_4096_dyad32_only
Epoch 4/100
2450/2450 - 28s - loss: 2.0748 - accuracy: 0.1371 - val_loss: 2.0715 - val_accuracy: 0.1354

Epoch 00004: val_loss improved from 2.07696 to 2.07146, saving model to ./weights_folder/fusion_4096_dyad32_only
Epoch 5/100
2450/2450 - 27s - loss: 2.0532 - accuracy: 0.1579 - val_loss: 2.0318 - val_accuracy: 0.1700

Epoch 00005: val_loss improved from 2.07146 to 2.03183, saving model to ./weights_folder/fusion_4096_dyad32_only
Epoch 6/100
2450/2450 - 26s - loss: 2.0330 - accuracy: 0.1703 - val_loss: 2.0135 - val_accuracy: 0.1809

Epoch 00006: val_loss improved from 2.03183 to 2.01349, saving model to ./weights_folder/fusion_4096_dyad32_only
Epoch 7/100
2450/2450 - 29s - loss: 2.0224 - accuracy: 0.1770 - val_loss: 2.0115 - val_accuracy: 0.1805

Epoch 00007: val_loss improved from 2.01349 to 2.01154, saving model to ./weights_folder/fusion_4096_dyad32_only
Epoch 8/100
2450/2450 - 27s - loss: 2.0061 - accuracy: 0.1863 - val_loss: 2.0083 - val_accuracy: 0.1799

Epoch 00008: val_loss improved from 2.01154 to 2.00827, saving model to ./weights_folder/fusion_4096_dyad32_only
Epoch 9/100
2450/2450 - 27s - loss: 1.9752 - accuracy: 0.1973 - val_loss: 1.9513 - val_accuracy: 0.2018

Epoch 00009: val_loss improved from 2.00827 to 1.95128, saving model to ./weights_folder/fusion_4096_dyad32_only
Epoch 10/100
2450/2450 - 28s - loss: 1.9646 - accuracy: 0.2011 - val_loss: 1.9349 - val_accuracy: 0.2095

Epoch 00010: val_loss improved from 1.95128 to 1.93486, saving model to ./weights_folder/fusion_4096_dyad32_only
Epoch 11/100
2450/2450 - 30s - loss: 1.9570 - accuracy: 0.2029 - val_loss: 1.9351 - val_accuracy: 0.2103

Epoch 00011: val_loss did not improve from 1.93486
Epoch 12/100
2450/2450 - 28s - loss: 1.9502 - accuracy: 0.2076 - val_loss: 1.9371 - val_accuracy: 0.2091

Epoch 00012: val_loss did not improve from 1.93486
Epoch 13/100
2450/2450 - 28s - loss: 1.9421 - accuracy: 0.2084 - val_loss: 1.9066 - val_accuracy: 0.2219

Epoch 00013: val_loss improved from 1.93486 to 1.90664, saving model to ./weights_folder/fusion_4096_dyad32_only
Epoch 14/100
2450/2450 - 27s - loss: 1.9281 - accuracy: 0.2133 - val_loss: 1.8844 - val_accuracy: 0.2240

Epoch 00014: val_loss improved from 1.90664 to 1.88440, saving model to ./weights_folder/fusion_4096_dyad32_only
Epoch 15/100
2450/2450 - 28s - loss: 1.9177 - accuracy: 0.2148 - val_loss: 1.8713 - val_accuracy: 0.2254

Epoch 00015: val_loss improved from 1.88440 to 1.87135, saving model to ./weights_folder/fusion_4096_dyad32_only
Epoch 16/100
2450/2450 - 27s - loss: 1.9063 - accuracy: 0.2201 - val_loss: 1.8533 - val_accuracy: 0.2332

Epoch 00016: val_loss improved from 1.87135 to 1.85326, saving model to ./weights_folder/fusion_4096_dyad32_only
Epoch 17/100
2450/2450 - 26s - loss: 1.8943 - accuracy: 0.2232 - val_loss: 1.8407 - val_accuracy: 0.2343

Epoch 00017: val_loss improved from 1.85326 to 1.84071, saving model to ./weights_folder/fusion_4096_dyad32_only
Epoch 18/100
2450/2450 - 27s - loss: 1.8864 - accuracy: 0.2263 - val_loss: 1.8297 - val_accuracy: 0.2365

Epoch 00018: val_loss improved from 1.84071 to 1.82970, saving model to ./weights_folder/fusion_4096_dyad32_only
Epoch 19/100
2450/2450 - 27s - loss: 1.8832 - accuracy: 0.2272 - val_loss: 1.8291 - val_accuracy: 0.2359

Epoch 00019: val_loss improved from 1.82970 to 1.82912, saving model to ./weights_folder/fusion_4096_dyad32_only
Epoch 20/100
2450/2450 - 28s - loss: 1.8770 - accuracy: 0.2291 - val_loss: 1.8219 - val_accuracy: 0.2381

Epoch 00020: val_loss improved from 1.82912 to 1.82191, saving model to ./weights_folder/fusion_4096_dyad32_only
Epoch 21/100
2450/2450 - 26s - loss: 1.8726 - accuracy: 0.2302 - val_loss: 1.8129 - val_accuracy: 0.2464

Epoch 00021: val_loss improved from 1.82191 to 1.81292, saving model to ./weights_folder/fusion_4096_dyad32_only
Epoch 22/100
2450/2450 - 27s - loss: 1.8678 - accuracy: 0.2328 - val_loss: 1.8193 - val_accuracy: 0.2396

Epoch 00022: val_loss did not improve from 1.81292
Epoch 23/100
2450/2450 - 27s - loss: 1.8653 - accuracy: 0.2350 - val_loss: 1.8152 - val_accuracy: 0.2434

Epoch 00023: val_loss did not improve from 1.81292
Epoch 24/100
2450/2450 - 26s - loss: 1.8647 - accuracy: 0.2366 - val_loss: 1.8104 - val_accuracy: 0.2419

Epoch 00024: val_loss improved from 1.81292 to 1.81041, saving model to ./weights_folder/fusion_4096_dyad32_only
Epoch 25/100
2450/2450 - 28s - loss: 1.8619 - accuracy: 0.2366 - val_loss: 1.8081 - val_accuracy: 0.2454

Epoch 00025: val_loss improved from 1.81041 to 1.80812, saving model to ./weights_folder/fusion_4096_dyad32_only
Epoch 26/100
2450/2450 - 26s - loss: 1.8583 - accuracy: 0.2378 - val_loss: 1.8083 - val_accuracy: 0.2470

Epoch 00026: val_loss did not improve from 1.80812
Epoch 27/100
2450/2450 - 27s - loss: 1.8586 - accuracy: 0.2399 - val_loss: 1.8096 - val_accuracy: 0.2446

Epoch 00027: val_loss did not improve from 1.80812
Epoch 28/100
2450/2450 - 27s - loss: 1.8586 - accuracy: 0.2421 - val_loss: 1.8094 - val_accuracy: 0.2421

Epoch 00028: val_loss did not improve from 1.80812
Epoch 29/100
2450/2450 - 27s - loss: 1.8520 - accuracy: 0.2458 - val_loss: 1.8039 - val_accuracy: 0.2464

Epoch 00029: val_loss improved from 1.80812 to 1.80392, saving model to ./weights_folder/fusion_4096_dyad32_only
Epoch 30/100
2450/2450 - 28s - loss: 1.8518 - accuracy: 0.2420 - val_loss: 1.8047 - val_accuracy: 0.2457

Epoch 00030: val_loss did not improve from 1.80392
Epoch 31/100
2450/2450 - 28s - loss: 1.8541 - accuracy: 0.2448 - val_loss: 1.8022 - val_accuracy: 0.2518

Epoch 00031: val_loss improved from 1.80392 to 1.80216, saving model to ./weights_folder/fusion_4096_dyad32_only
Epoch 32/100
2450/2450 - 28s - loss: 1.8523 - accuracy: 0.2458 - val_loss: 1.8070 - val_accuracy: 0.2496

Epoch 00032: val_loss did not improve from 1.80216
Epoch 33/100
2450/2450 - 29s - loss: 1.8491 - accuracy: 0.2467 - val_loss: 1.8089 - val_accuracy: 0.2435

Epoch 00033: val_loss did not improve from 1.80216
Epoch 34/100
2450/2450 - 27s - loss: 1.8487 - accuracy: 0.2455 - val_loss: 1.8066 - val_accuracy: 0.2433

Epoch 00034: val_loss did not improve from 1.80216
Epoch 35/100
2450/2450 - 27s - loss: 1.8444 - accuracy: 0.2490 - val_loss: 1.8032 - val_accuracy: 0.2483

Epoch 00035: val_loss did not improve from 1.80216
Epoch 36/100
2450/2450 - 27s - loss: 1.8447 - accuracy: 0.2499 - val_loss: 1.8069 - val_accuracy: 0.2425

Epoch 00036: val_loss did not improve from 1.80216
Epoch 37/100
2450/2450 - 29s - loss: 1.8438 - accuracy: 0.2509 - val_loss: 1.8094 - val_accuracy: 0.2430

Epoch 00037: val_loss did not improve from 1.80216
Epoch 38/100
2450/2450 - 29s - loss: 1.8428 - accuracy: 0.2511 - val_loss: 1.7962 - val_accuracy: 0.2547

Epoch 00038: val_loss improved from 1.80216 to 1.79619, saving model to ./weights_folder/fusion_4096_dyad32_only
Epoch 39/100
2450/2450 - 27s - loss: 1.8393 - accuracy: 0.2522 - val_loss: 1.7967 - val_accuracy: 0.2505

Epoch 00039: val_loss did not improve from 1.79619
Epoch 40/100
2450/2450 - 27s - loss: 1.8397 - accuracy: 0.2537 - val_loss: 1.8001 - val_accuracy: 0.2455

Epoch 00040: val_loss did not improve from 1.79619
Epoch 41/100
2450/2450 - 27s - loss: 1.8404 - accuracy: 0.2532 - val_loss: 1.7997 - val_accuracy: 0.2461

Epoch 00041: val_loss did not improve from 1.79619
Epoch 42/100
2450/2450 - 29s - loss: 1.8355 - accuracy: 0.2554 - val_loss: 1.7998 - val_accuracy: 0.2524

Epoch 00042: val_loss did not improve from 1.79619
Epoch 43/100
2450/2450 - 27s - loss: 1.8378 - accuracy: 0.2548 - val_loss: 1.7994 - val_accuracy: 0.2527

Epoch 00043: val_loss did not improve from 1.79619
Epoch 44/100
2450/2450 - 30s - loss: 1.8380 - accuracy: 0.2567 - val_loss: 1.8079 - val_accuracy: 0.2455

Epoch 00044: val_loss did not improve from 1.79619
Epoch 45/100
2450/2450 - 29s - loss: 1.8349 - accuracy: 0.2582 - val_loss: 1.7984 - val_accuracy: 0.2530

Epoch 00045: val_loss did not improve from 1.79619
Epoch 46/100
2450/2450 - 29s - loss: 1.8316 - accuracy: 0.2588 - val_loss: 1.8007 - val_accuracy: 0.2558

Epoch 00046: val_loss did not improve from 1.79619
Epoch 47/100
2450/2450 - 29s - loss: 1.8303 - accuracy: 0.2599 - val_loss: 1.8009 - val_accuracy: 0.2460

Epoch 00047: val_loss did not improve from 1.79619
Epoch 48/100
2450/2450 - 26s - loss: 1.8300 - accuracy: 0.2616 - val_loss: 1.7960 - val_accuracy: 0.2551

Epoch 00048: val_loss improved from 1.79619 to 1.79603, saving model to ./weights_folder/fusion_4096_dyad32_only
Epoch 49/100
2450/2450 - 27s - loss: 1.8324 - accuracy: 0.2583 - val_loss: 1.8054 - val_accuracy: 0.2444

Epoch 00049: val_loss did not improve from 1.79603
Epoch 50/100
2450/2450 - 27s - loss: 1.8298 - accuracy: 0.2612 - val_loss: 1.8007 - val_accuracy: 0.2496

Epoch 00050: val_loss did not improve from 1.79603
Epoch 51/100
2450/2450 - 28s - loss: 1.8298 - accuracy: 0.2584 - val_loss: 1.7980 - val_accuracy: 0.2540

Epoch 00051: val_loss did not improve from 1.79603
Epoch 52/100
2450/2450 - 26s - loss: 1.8295 - accuracy: 0.2607 - val_loss: 1.7973 - val_accuracy: 0.2490

Epoch 00052: val_loss did not improve from 1.79603
Epoch 53/100
2450/2450 - 26s - loss: 1.8270 - accuracy: 0.2635 - val_loss: 1.7988 - val_accuracy: 0.2491

Epoch 00053: val_loss did not improve from 1.79603
Epoch 54/100
2450/2450 - 27s - loss: 1.8275 - accuracy: 0.2610 - val_loss: 1.7961 - val_accuracy: 0.2501

Epoch 00054: val_loss did not improve from 1.79603
Epoch 55/100
2450/2450 - 29s - loss: 1.8252 - accuracy: 0.2626 - val_loss: 1.8040 - val_accuracy: 0.2464

Epoch 00055: val_loss did not improve from 1.79603
Epoch 56/100
2450/2450 - 27s - loss: 1.8252 - accuracy: 0.2622 - val_loss: 1.8024 - val_accuracy: 0.2493

Epoch 00056: val_loss did not improve from 1.79603
Epoch 57/100
2450/2450 - 26s - loss: 1.8232 - accuracy: 0.2635 - val_loss: 1.8030 - val_accuracy: 0.2483

Epoch 00057: val_loss did not improve from 1.79603
Epoch 58/100
2450/2450 - 28s - loss: 1.8203 - accuracy: 0.2672 - val_loss: 1.7991 - val_accuracy: 0.2475

Epoch 00058: val_loss did not improve from 1.79603
Epoch 00058: early stopping
training time:  2390.5601370334625 seconds 
end of training
 
Loading model
end of loading
 
Evaluating model
   1/1050 [..............................] - ETA: 4:00 - loss: 1.7728 - accuracy: 0.2500  14/1050 [..............................] - ETA: 4s - loss: 1.8273 - accuracy: 0.2210    27/1050 [..............................] - ETA: 4s - loss: 1.8050 - accuracy: 0.2396  40/1050 [>.............................] - ETA: 4s - loss: 1.8094 - accuracy: 0.2383  53/1050 [>.............................] - ETA: 3s - loss: 1.8092 - accuracy: 0.2412  66/1050 [>.............................] - ETA: 3s - loss: 1.8089 - accuracy: 0.2420  79/1050 [=>............................] - ETA: 3s - loss: 1.8063 - accuracy: 0.2476  92/1050 [=>............................] - ETA: 3s - loss: 1.8019 - accuracy: 0.2520 106/1050 [==>...........................] - ETA: 3s - loss: 1.7984 - accuracy: 0.2518 119/1050 [==>...........................] - ETA: 3s - loss: 1.7984 - accuracy: 0.2529 133/1050 [==>...........................] - ETA: 3s - loss: 1.7975 - accuracy: 0.2509 146/1050 [===>..........................] - ETA: 3s - loss: 1.7942 - accuracy: 0.2534 159/1050 [===>..........................] - ETA: 3s - loss: 1.7945 - accuracy: 0.2543 172/1050 [===>..........................] - ETA: 3s - loss: 1.7938 - accuracy: 0.2533 185/1050 [====>.........................] - ETA: 3s - loss: 1.7930 - accuracy: 0.2541 198/1050 [====>.........................] - ETA: 3s - loss: 1.7932 - accuracy: 0.2554 211/1050 [=====>........................] - ETA: 3s - loss: 1.7941 - accuracy: 0.2555 224/1050 [=====>........................] - ETA: 3s - loss: 1.7933 - accuracy: 0.2559 237/1050 [=====>........................] - ETA: 3s - loss: 1.7931 - accuracy: 0.2549 250/1050 [======>.......................] - ETA: 3s - loss: 1.7930 - accuracy: 0.2530 264/1050 [======>.......................] - ETA: 3s - loss: 1.7947 - accuracy: 0.2538 278/1050 [======>.......................] - ETA: 3s - loss: 1.7926 - accuracy: 0.2556 291/1050 [=======>......................] - ETA: 2s - loss: 1.7917 - accuracy: 0.2556 304/1050 [=======>......................] - ETA: 2s - loss: 1.7918 - accuracy: 0.2549 317/1050 [========>.....................] - ETA: 2s - loss: 1.7929 - accuracy: 0.2538 330/1050 [========>.....................] - ETA: 2s - loss: 1.7940 - accuracy: 0.2537 343/1050 [========>.....................] - ETA: 2s - loss: 1.7940 - accuracy: 0.2531 356/1050 [=========>....................] - ETA: 2s - loss: 1.7926 - accuracy: 0.2540 369/1050 [=========>....................] - ETA: 2s - loss: 1.7927 - accuracy: 0.2541 382/1050 [=========>....................] - ETA: 2s - loss: 1.7935 - accuracy: 0.2542 395/1050 [==========>...................] - ETA: 2s - loss: 1.7923 - accuracy: 0.2546 408/1050 [==========>...................] - ETA: 2s - loss: 1.7905 - accuracy: 0.2558 422/1050 [===========>..................] - ETA: 2s - loss: 1.7918 - accuracy: 0.2543 435/1050 [===========>..................] - ETA: 2s - loss: 1.7907 - accuracy: 0.2547 448/1050 [===========>..................] - ETA: 2s - loss: 1.7919 - accuracy: 0.2546 461/1050 [============>.................] - ETA: 2s - loss: 1.7929 - accuracy: 0.2537 474/1050 [============>.................] - ETA: 2s - loss: 1.7916 - accuracy: 0.2547 488/1050 [============>.................] - ETA: 2s - loss: 1.7923 - accuracy: 0.2547 501/1050 [=============>................] - ETA: 2s - loss: 1.7914 - accuracy: 0.2555 514/1050 [=============>................] - ETA: 2s - loss: 1.7926 - accuracy: 0.2547 527/1050 [==============>...............] - ETA: 2s - loss: 1.7951 - accuracy: 0.2542 541/1050 [==============>...............] - ETA: 2s - loss: 1.7959 - accuracy: 0.2535 553/1050 [==============>...............] - ETA: 1s - loss: 1.7961 - accuracy: 0.2535 566/1050 [===============>..............] - ETA: 1s - loss: 1.7950 - accuracy: 0.2533 579/1050 [===============>..............] - ETA: 1s - loss: 1.7953 - accuracy: 0.2530 592/1050 [===============>..............] - ETA: 1s - loss: 1.7949 - accuracy: 0.2534 604/1050 [================>.............] - ETA: 1s - loss: 1.7945 - accuracy: 0.2534 616/1050 [================>.............] - ETA: 1s - loss: 1.7945 - accuracy: 0.2534 628/1050 [================>.............] - ETA: 1s - loss: 1.7951 - accuracy: 0.2539 639/1050 [=================>............] - ETA: 1s - loss: 1.7956 - accuracy: 0.2538 651/1050 [=================>............] - ETA: 1s - loss: 1.7956 - accuracy: 0.2539 663/1050 [=================>............] - ETA: 1s - loss: 1.7971 - accuracy: 0.2534 675/1050 [==================>...........] - ETA: 1s - loss: 1.7981 - accuracy: 0.2532 687/1050 [==================>...........] - ETA: 1s - loss: 1.7981 - accuracy: 0.2527 700/1050 [===================>..........] - ETA: 1s - loss: 1.7989 - accuracy: 0.2524 713/1050 [===================>..........] - ETA: 1s - loss: 1.7984 - accuracy: 0.2527 726/1050 [===================>..........] - ETA: 1s - loss: 1.7992 - accuracy: 0.2524 740/1050 [====================>.........] - ETA: 1s - loss: 1.7982 - accuracy: 0.2527 754/1050 [====================>.........] - ETA: 1s - loss: 1.7978 - accuracy: 0.2529 767/1050 [====================>.........] - ETA: 1s - loss: 1.7980 - accuracy: 0.2531 780/1050 [=====================>........] - ETA: 1s - loss: 1.7979 - accuracy: 0.2536 793/1050 [=====================>........] - ETA: 1s - loss: 1.7980 - accuracy: 0.2538 806/1050 [======================>.......] - ETA: 0s - loss: 1.7976 - accuracy: 0.2535 819/1050 [======================>.......] - ETA: 0s - loss: 1.7970 - accuracy: 0.2536 832/1050 [======================>.......] - ETA: 0s - loss: 1.7971 - accuracy: 0.2533 845/1050 [=======================>......] - ETA: 0s - loss: 1.7965 - accuracy: 0.2539 858/1050 [=======================>......] - ETA: 0s - loss: 1.7970 - accuracy: 0.2538 872/1050 [=======================>......] - ETA: 0s - loss: 1.7967 - accuracy: 0.2542 885/1050 [========================>.....] - ETA: 0s - loss: 1.7959 - accuracy: 0.2543 898/1050 [========================>.....] - ETA: 0s - loss: 1.7960 - accuracy: 0.2544 912/1050 [=========================>....] - ETA: 0s - loss: 1.7964 - accuracy: 0.2541 926/1050 [=========================>....] - ETA: 0s - loss: 1.7967 - accuracy: 0.2540 939/1050 [=========================>....] - ETA: 0s - loss: 1.7971 - accuracy: 0.2542 952/1050 [==========================>...] - ETA: 0s - loss: 1.7969 - accuracy: 0.2543 965/1050 [==========================>...] - ETA: 0s - loss: 1.7966 - accuracy: 0.2541 978/1050 [==========================>...] - ETA: 0s - loss: 1.7964 - accuracy: 0.2541 991/1050 [===========================>..] - ETA: 0s - loss: 1.7961 - accuracy: 0.25431005/1050 [===========================>..] - ETA: 0s - loss: 1.7963 - accuracy: 0.25431018/1050 [============================>.] - ETA: 0s - loss: 1.7962 - accuracy: 0.25411031/1050 [============================>.] - ETA: 0s - loss: 1.7960 - accuracy: 0.25451044/1050 [============================>.] - ETA: 0s - loss: 1.7957 - accuracy: 0.25501050/1050 [==============================] - 4s 4ms/step - loss: 1.7960 - accuracy: 0.2551
end of evaluation
 
score:  [1.7960275411605835, 0.25505951046943665]
job end at Thu Feb 29 15:53:29 CET 2024
