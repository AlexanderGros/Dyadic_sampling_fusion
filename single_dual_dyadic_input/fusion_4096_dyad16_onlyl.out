  1) releases/2021b
job start at Wed Feb 28 10:20:15 CET 2024
2024-02-28 10:20:18.887192: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-28 10:20:18.888020: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.
2024-02-28 10:20:19.018356: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-28 10:20:19.018758: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2600000000 Hz
 
first y shape:  (112000, 8)
datagenerator definition successfull
start AI architecture definition
Model: "model"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input5 (InputLayer)          [(None, 2, 256, 1)]       0         
_________________________________________________________________
conv2d (Conv2D)              (None, 1, 249, 40)        680       
_________________________________________________________________
dropout (Dropout)            (None, 1, 249, 40)        0         
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 1, 246, 40)        6440      
_________________________________________________________________
dropout_1 (Dropout)          (None, 1, 246, 40)        0         
_________________________________________________________________
flatten (Flatten)            (None, 9840)              0         
_________________________________________________________________
dense1 (Dense)               (None, 128)               1259648   
_________________________________________________________________
dense2 (Dense)               (None, 8)                 1032      
_________________________________________________________________
reshape (Reshape)            (None, 8)                 0         
=================================================================
Total params: 1,267,800
Trainable params: 1,267,800
Non-trainable params: 0
_________________________________________________________________
end of architecture
 
Training start
Epoch 1/100
2450/2450 - 72s - loss: 2.0727 - accuracy: 0.1422 - val_loss: 2.0390 - val_accuracy: 0.1895
2024-02-28 10:21:31.135385: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.

Epoch 00001: val_loss improved from inf to 2.03896, saving model to ./weights_folder/fusion_4096_dyad16_only
Epoch 2/100
2450/2450 - 69s - loss: 1.9741 - accuracy: 0.2104 - val_loss: 1.9108 - val_accuracy: 0.2311

Epoch 00002: val_loss improved from 2.03896 to 1.91076, saving model to ./weights_folder/fusion_4096_dyad16_only
Epoch 3/100
2450/2450 - 68s - loss: 1.7998 - accuracy: 0.2722 - val_loss: 1.7509 - val_accuracy: 0.2909

Epoch 00003: val_loss improved from 1.91076 to 1.75089, saving model to ./weights_folder/fusion_4096_dyad16_only
Epoch 4/100
2450/2450 - 69s - loss: 1.7593 - accuracy: 0.2865 - val_loss: 1.7162 - val_accuracy: 0.2980

Epoch 00004: val_loss improved from 1.75089 to 1.71615, saving model to ./weights_folder/fusion_4096_dyad16_only
Epoch 5/100
2450/2450 - 69s - loss: 1.7349 - accuracy: 0.2986 - val_loss: 1.7081 - val_accuracy: 0.3000

Epoch 00005: val_loss improved from 1.71615 to 1.70805, saving model to ./weights_folder/fusion_4096_dyad16_only
Epoch 6/100
2450/2450 - 70s - loss: 1.7134 - accuracy: 0.3109 - val_loss: 1.6841 - val_accuracy: 0.3093

Epoch 00006: val_loss improved from 1.70805 to 1.68406, saving model to ./weights_folder/fusion_4096_dyad16_only
Epoch 7/100
2450/2450 - 68s - loss: 1.6934 - accuracy: 0.3178 - val_loss: 1.6755 - val_accuracy: 0.3146

Epoch 00007: val_loss improved from 1.68406 to 1.67552, saving model to ./weights_folder/fusion_4096_dyad16_only
Epoch 8/100
2450/2450 - 69s - loss: 1.6766 - accuracy: 0.3272 - val_loss: 1.6805 - val_accuracy: 0.3144

Epoch 00008: val_loss did not improve from 1.67552
Epoch 9/100
2450/2450 - 68s - loss: 1.6617 - accuracy: 0.3346 - val_loss: 1.6571 - val_accuracy: 0.3237

Epoch 00009: val_loss improved from 1.67552 to 1.65713, saving model to ./weights_folder/fusion_4096_dyad16_only
Epoch 10/100
2450/2450 - 69s - loss: 1.6500 - accuracy: 0.3407 - val_loss: 1.6577 - val_accuracy: 0.3245

Epoch 00010: val_loss did not improve from 1.65713
Epoch 11/100
2450/2450 - 69s - loss: 1.6343 - accuracy: 0.3510 - val_loss: 1.6486 - val_accuracy: 0.3286

Epoch 00011: val_loss improved from 1.65713 to 1.64862, saving model to ./weights_folder/fusion_4096_dyad16_only
Epoch 12/100
2450/2450 - 68s - loss: 1.6253 - accuracy: 0.3518 - val_loss: 1.6705 - val_accuracy: 0.3192

Epoch 00012: val_loss did not improve from 1.64862
Epoch 13/100
2450/2450 - 69s - loss: 1.6133 - accuracy: 0.3580 - val_loss: 1.6487 - val_accuracy: 0.3296

Epoch 00013: val_loss did not improve from 1.64862
Epoch 14/100
2450/2450 - 69s - loss: 1.6057 - accuracy: 0.3629 - val_loss: 1.6454 - val_accuracy: 0.3362

Epoch 00014: val_loss improved from 1.64862 to 1.64539, saving model to ./weights_folder/fusion_4096_dyad16_only
Epoch 15/100
2450/2450 - 69s - loss: 1.5959 - accuracy: 0.3702 - val_loss: 1.6379 - val_accuracy: 0.3369

Epoch 00015: val_loss improved from 1.64539 to 1.63793, saving model to ./weights_folder/fusion_4096_dyad16_only
Epoch 16/100
2450/2450 - 69s - loss: 1.5868 - accuracy: 0.3721 - val_loss: 1.6377 - val_accuracy: 0.3374

Epoch 00016: val_loss improved from 1.63793 to 1.63773, saving model to ./weights_folder/fusion_4096_dyad16_only
Epoch 17/100
2450/2450 - 69s - loss: 1.5782 - accuracy: 0.3780 - val_loss: 1.6460 - val_accuracy: 0.3313

Epoch 00017: val_loss did not improve from 1.63773
Epoch 18/100
2450/2450 - 69s - loss: 1.5718 - accuracy: 0.3799 - val_loss: 1.6387 - val_accuracy: 0.3351

Epoch 00018: val_loss did not improve from 1.63773
Epoch 19/100
2450/2450 - 68s - loss: 1.5637 - accuracy: 0.3832 - val_loss: 1.6337 - val_accuracy: 0.3436

Epoch 00019: val_loss improved from 1.63773 to 1.63372, saving model to ./weights_folder/fusion_4096_dyad16_only
Epoch 20/100
2450/2450 - 69s - loss: 1.5582 - accuracy: 0.3885 - val_loss: 1.6378 - val_accuracy: 0.3393

Epoch 00020: val_loss did not improve from 1.63372
Epoch 21/100
2450/2450 - 68s - loss: 1.5522 - accuracy: 0.3921 - val_loss: 1.6847 - val_accuracy: 0.3289

Epoch 00021: val_loss did not improve from 1.63372
Epoch 22/100
2450/2450 - 69s - loss: 1.5413 - accuracy: 0.3971 - val_loss: 1.6373 - val_accuracy: 0.3407

Epoch 00022: val_loss did not improve from 1.63372
Epoch 23/100
2450/2450 - 68s - loss: 1.5373 - accuracy: 0.3989 - val_loss: 1.6292 - val_accuracy: 0.3468

Epoch 00023: val_loss improved from 1.63372 to 1.62918, saving model to ./weights_folder/fusion_4096_dyad16_only
Epoch 24/100
2450/2450 - 69s - loss: 1.5330 - accuracy: 0.3996 - val_loss: 1.6281 - val_accuracy: 0.3478

Epoch 00024: val_loss improved from 1.62918 to 1.62809, saving model to ./weights_folder/fusion_4096_dyad16_only
Epoch 25/100
2450/2450 - 69s - loss: 1.5236 - accuracy: 0.4069 - val_loss: 1.6214 - val_accuracy: 0.3504

Epoch 00025: val_loss improved from 1.62809 to 1.62141, saving model to ./weights_folder/fusion_4096_dyad16_only
Epoch 26/100
2450/2450 - 69s - loss: 1.5163 - accuracy: 0.4089 - val_loss: 1.6337 - val_accuracy: 0.3446

Epoch 00026: val_loss did not improve from 1.62141
Epoch 27/100
2450/2450 - 70s - loss: 1.5152 - accuracy: 0.4084 - val_loss: 1.6268 - val_accuracy: 0.3466

Epoch 00027: val_loss did not improve from 1.62141
Epoch 28/100
2450/2450 - 69s - loss: 1.5110 - accuracy: 0.4125 - val_loss: 1.6276 - val_accuracy: 0.3486

Epoch 00028: val_loss did not improve from 1.62141
Epoch 29/100
2450/2450 - 69s - loss: 1.5035 - accuracy: 0.4171 - val_loss: 1.6087 - val_accuracy: 0.3588

Epoch 00029: val_loss improved from 1.62141 to 1.60867, saving model to ./weights_folder/fusion_4096_dyad16_only
Epoch 30/100
2450/2450 - 70s - loss: 1.4985 - accuracy: 0.4180 - val_loss: 1.6214 - val_accuracy: 0.3494

Epoch 00030: val_loss did not improve from 1.60867
Epoch 31/100
2450/2450 - 69s - loss: 1.5001 - accuracy: 0.4170 - val_loss: 1.6397 - val_accuracy: 0.3441

Epoch 00031: val_loss did not improve from 1.60867
Epoch 32/100
2450/2450 - 68s - loss: 1.4931 - accuracy: 0.4216 - val_loss: 1.6712 - val_accuracy: 0.3379

Epoch 00032: val_loss did not improve from 1.60867
Epoch 33/100
2450/2450 - 68s - loss: 1.4850 - accuracy: 0.4258 - val_loss: 1.6097 - val_accuracy: 0.3576

Epoch 00033: val_loss did not improve from 1.60867
Epoch 34/100
2450/2450 - 70s - loss: 1.4794 - accuracy: 0.4276 - val_loss: 1.6364 - val_accuracy: 0.3476

Epoch 00034: val_loss did not improve from 1.60867
Epoch 35/100
2450/2450 - 70s - loss: 1.4763 - accuracy: 0.4304 - val_loss: 1.6125 - val_accuracy: 0.3582

Epoch 00035: val_loss did not improve from 1.60867
Epoch 36/100
2450/2450 - 69s - loss: 1.4732 - accuracy: 0.4304 - val_loss: 1.6246 - val_accuracy: 0.3504

Epoch 00036: val_loss did not improve from 1.60867
Epoch 37/100
2450/2450 - 69s - loss: 1.4695 - accuracy: 0.4347 - val_loss: 1.6126 - val_accuracy: 0.3571

Epoch 00037: val_loss did not improve from 1.60867
Epoch 38/100
2450/2450 - 68s - loss: 1.4594 - accuracy: 0.4377 - val_loss: 1.5993 - val_accuracy: 0.3635

Epoch 00038: val_loss improved from 1.60867 to 1.59931, saving model to ./weights_folder/fusion_4096_dyad16_only
Epoch 39/100
2450/2450 - 69s - loss: 1.4599 - accuracy: 0.4373 - val_loss: 1.6169 - val_accuracy: 0.3562

Epoch 00039: val_loss did not improve from 1.59931
Epoch 40/100
2450/2450 - 69s - loss: 1.4566 - accuracy: 0.4387 - val_loss: 1.6154 - val_accuracy: 0.3578

Epoch 00040: val_loss did not improve from 1.59931
Epoch 41/100
2450/2450 - 69s - loss: 1.4514 - accuracy: 0.4411 - val_loss: 1.6111 - val_accuracy: 0.3626

Epoch 00041: val_loss did not improve from 1.59931
Epoch 42/100
2450/2450 - 68s - loss: 1.4475 - accuracy: 0.4440 - val_loss: 1.5940 - val_accuracy: 0.3698

Epoch 00042: val_loss improved from 1.59931 to 1.59402, saving model to ./weights_folder/fusion_4096_dyad16_only
Epoch 43/100
2450/2450 - 68s - loss: 1.4461 - accuracy: 0.4440 - val_loss: 1.6248 - val_accuracy: 0.3598

Epoch 00043: val_loss did not improve from 1.59402
Epoch 44/100
2450/2450 - 69s - loss: 1.4385 - accuracy: 0.4480 - val_loss: 1.6062 - val_accuracy: 0.3622

Epoch 00044: val_loss did not improve from 1.59402
Epoch 45/100
2450/2450 - 69s - loss: 1.4430 - accuracy: 0.4457 - val_loss: 1.5973 - val_accuracy: 0.3703

Epoch 00045: val_loss did not improve from 1.59402
Epoch 46/100
2450/2450 - 69s - loss: 1.4321 - accuracy: 0.4511 - val_loss: 1.6030 - val_accuracy: 0.3682

Epoch 00046: val_loss did not improve from 1.59402
Epoch 47/100
2450/2450 - 70s - loss: 1.4288 - accuracy: 0.4496 - val_loss: 1.5952 - val_accuracy: 0.3668

Epoch 00047: val_loss did not improve from 1.59402
Epoch 48/100
2450/2450 - 69s - loss: 1.4264 - accuracy: 0.4551 - val_loss: 1.6172 - val_accuracy: 0.3552

Epoch 00048: val_loss did not improve from 1.59402
Epoch 49/100
2450/2450 - 70s - loss: 1.4235 - accuracy: 0.4581 - val_loss: 1.6184 - val_accuracy: 0.3564

Epoch 00049: val_loss did not improve from 1.59402
Epoch 50/100
2450/2450 - 69s - loss: 1.4175 - accuracy: 0.4570 - val_loss: 1.5831 - val_accuracy: 0.3739

Epoch 00050: val_loss improved from 1.59402 to 1.58308, saving model to ./weights_folder/fusion_4096_dyad16_only
Epoch 51/100
2450/2450 - 69s - loss: 1.4090 - accuracy: 0.4601 - val_loss: 1.6175 - val_accuracy: 0.3565

Epoch 00051: val_loss did not improve from 1.58308
Epoch 52/100
2450/2450 - 70s - loss: 1.4120 - accuracy: 0.4610 - val_loss: 1.6220 - val_accuracy: 0.3581

Epoch 00052: val_loss did not improve from 1.58308
Epoch 53/100
2450/2450 - 69s - loss: 1.4104 - accuracy: 0.4619 - val_loss: 1.6152 - val_accuracy: 0.3554

Epoch 00053: val_loss did not improve from 1.58308
Epoch 54/100
2450/2450 - 72s - loss: 1.4047 - accuracy: 0.4646 - val_loss: 1.5905 - val_accuracy: 0.3680

Epoch 00054: val_loss did not improve from 1.58308
Epoch 55/100
2450/2450 - 69s - loss: 1.3971 - accuracy: 0.4669 - val_loss: 1.6116 - val_accuracy: 0.3646

Epoch 00055: val_loss did not improve from 1.58308
Epoch 56/100
2450/2450 - 70s - loss: 1.3975 - accuracy: 0.4659 - val_loss: 1.6088 - val_accuracy: 0.3658

Epoch 00056: val_loss did not improve from 1.58308
Epoch 57/100
2450/2450 - 69s - loss: 1.3938 - accuracy: 0.4696 - val_loss: 1.5901 - val_accuracy: 0.3709

Epoch 00057: val_loss did not improve from 1.58308
Epoch 58/100
2450/2450 - 69s - loss: 1.3903 - accuracy: 0.4714 - val_loss: 1.6034 - val_accuracy: 0.3701

Epoch 00058: val_loss did not improve from 1.58308
Epoch 59/100
2450/2450 - 69s - loss: 1.3869 - accuracy: 0.4734 - val_loss: 1.5970 - val_accuracy: 0.3648

Epoch 00059: val_loss did not improve from 1.58308
Epoch 60/100
2450/2450 - 69s - loss: 1.3843 - accuracy: 0.4741 - val_loss: 1.6006 - val_accuracy: 0.3692

Epoch 00060: val_loss did not improve from 1.58308
Epoch 00060: early stopping
training time:  4168.348605155945 seconds 
end of training
 
Loading model
end of loading
 
Evaluating model
   1/1050 [..............................] - ETA: 4:14 - loss: 1.8396 - accuracy: 0.2500  10/1050 [..............................] - ETA: 5s - loss: 1.5291 - accuracy: 0.3688    20/1050 [..............................] - ETA: 5s - loss: 1.5262 - accuracy: 0.3781  30/1050 [..............................] - ETA: 5s - loss: 1.5225 - accuracy: 0.3917  40/1050 [>.............................] - ETA: 5s - loss: 1.5267 - accuracy: 0.3867  50/1050 [>.............................] - ETA: 5s - loss: 1.5425 - accuracy: 0.3800  60/1050 [>.............................] - ETA: 5s - loss: 1.5430 - accuracy: 0.3854  70/1050 [=>............................] - ETA: 5s - loss: 1.5421 - accuracy: 0.3817  80/1050 [=>............................] - ETA: 5s - loss: 1.5525 - accuracy: 0.3777  90/1050 [=>............................] - ETA: 5s - loss: 1.5583 - accuracy: 0.3722 100/1050 [=>............................] - ETA: 5s - loss: 1.5593 - accuracy: 0.3744 110/1050 [==>...........................] - ETA: 4s - loss: 1.5612 - accuracy: 0.3719 120/1050 [==>...........................] - ETA: 4s - loss: 1.5582 - accuracy: 0.3737 130/1050 [==>...........................] - ETA: 4s - loss: 1.5599 - accuracy: 0.3738 140/1050 [===>..........................] - ETA: 4s - loss: 1.5620 - accuracy: 0.3732 150/1050 [===>..........................] - ETA: 4s - loss: 1.5617 - accuracy: 0.3740 160/1050 [===>..........................] - ETA: 4s - loss: 1.5542 - accuracy: 0.3783 170/1050 [===>..........................] - ETA: 4s - loss: 1.5532 - accuracy: 0.3801 180/1050 [====>.........................] - ETA: 4s - loss: 1.5537 - accuracy: 0.3792 190/1050 [====>.........................] - ETA: 4s - loss: 1.5555 - accuracy: 0.3786 200/1050 [====>.........................] - ETA: 4s - loss: 1.5558 - accuracy: 0.3808 210/1050 [=====>........................] - ETA: 4s - loss: 1.5571 - accuracy: 0.3799 220/1050 [=====>........................] - ETA: 4s - loss: 1.5614 - accuracy: 0.3784 230/1050 [=====>........................] - ETA: 4s - loss: 1.5607 - accuracy: 0.3807 240/1050 [=====>........................] - ETA: 4s - loss: 1.5593 - accuracy: 0.3811 250/1050 [======>.......................] - ETA: 4s - loss: 1.5630 - accuracy: 0.3801 260/1050 [======>.......................] - ETA: 4s - loss: 1.5638 - accuracy: 0.3796 270/1050 [======>.......................] - ETA: 4s - loss: 1.5632 - accuracy: 0.3804 280/1050 [=======>......................] - ETA: 4s - loss: 1.5635 - accuracy: 0.3804 290/1050 [=======>......................] - ETA: 3s - loss: 1.5625 - accuracy: 0.3819 300/1050 [=======>......................] - ETA: 3s - loss: 1.5612 - accuracy: 0.3824 310/1050 [=======>......................] - ETA: 3s - loss: 1.5609 - accuracy: 0.3834 320/1050 [========>.....................] - ETA: 3s - loss: 1.5597 - accuracy: 0.3845 330/1050 [========>.....................] - ETA: 3s - loss: 1.5602 - accuracy: 0.3838 340/1050 [========>.....................] - ETA: 3s - loss: 1.5619 - accuracy: 0.3833 350/1050 [=========>....................] - ETA: 3s - loss: 1.5649 - accuracy: 0.3812 360/1050 [=========>....................] - ETA: 3s - loss: 1.5640 - accuracy: 0.3818 370/1050 [=========>....................] - ETA: 3s - loss: 1.5623 - accuracy: 0.3829 380/1050 [=========>....................] - ETA: 3s - loss: 1.5639 - accuracy: 0.3822 390/1050 [==========>...................] - ETA: 3s - loss: 1.5658 - accuracy: 0.3809 400/1050 [==========>...................] - ETA: 3s - loss: 1.5671 - accuracy: 0.3805 410/1050 [==========>...................] - ETA: 3s - loss: 1.5669 - accuracy: 0.3807 420/1050 [===========>..................] - ETA: 3s - loss: 1.5688 - accuracy: 0.3800 430/1050 [===========>..................] - ETA: 3s - loss: 1.5699 - accuracy: 0.3794 440/1050 [===========>..................] - ETA: 3s - loss: 1.5714 - accuracy: 0.3783 450/1050 [===========>..................] - ETA: 3s - loss: 1.5715 - accuracy: 0.3783 460/1050 [============>.................] - ETA: 3s - loss: 1.5719 - accuracy: 0.3773 470/1050 [============>.................] - ETA: 3s - loss: 1.5713 - accuracy: 0.3769 480/1050 [============>.................] - ETA: 2s - loss: 1.5723 - accuracy: 0.3766 490/1050 [=============>................] - ETA: 2s - loss: 1.5719 - accuracy: 0.3775 500/1050 [=============>................] - ETA: 2s - loss: 1.5710 - accuracy: 0.3774 510/1050 [=============>................] - ETA: 2s - loss: 1.5704 - accuracy: 0.3775 520/1050 [=============>................] - ETA: 2s - loss: 1.5710 - accuracy: 0.3771 530/1050 [==============>...............] - ETA: 2s - loss: 1.5713 - accuracy: 0.3773 540/1050 [==============>...............] - ETA: 2s - loss: 1.5711 - accuracy: 0.3775 550/1050 [==============>...............] - ETA: 2s - loss: 1.5730 - accuracy: 0.3767 560/1050 [===============>..............] - ETA: 2s - loss: 1.5731 - accuracy: 0.3762 570/1050 [===============>..............] - ETA: 2s - loss: 1.5736 - accuracy: 0.3764 580/1050 [===============>..............] - ETA: 2s - loss: 1.5734 - accuracy: 0.3765 590/1050 [===============>..............] - ETA: 2s - loss: 1.5725 - accuracy: 0.3762 600/1050 [================>.............] - ETA: 2s - loss: 1.5734 - accuracy: 0.3763 610/1050 [================>.............] - ETA: 2s - loss: 1.5733 - accuracy: 0.3765 620/1050 [================>.............] - ETA: 2s - loss: 1.5717 - accuracy: 0.3776 630/1050 [=================>............] - ETA: 2s - loss: 1.5731 - accuracy: 0.3774 640/1050 [=================>............] - ETA: 2s - loss: 1.5736 - accuracy: 0.3773 650/1050 [=================>............] - ETA: 2s - loss: 1.5749 - accuracy: 0.3764 660/1050 [=================>............] - ETA: 2s - loss: 1.5746 - accuracy: 0.3768 670/1050 [==================>...........] - ETA: 1s - loss: 1.5746 - accuracy: 0.3770 680/1050 [==================>...........] - ETA: 1s - loss: 1.5751 - accuracy: 0.3773 691/1050 [==================>...........] - ETA: 1s - loss: 1.5769 - accuracy: 0.3763 701/1050 [===================>..........] - ETA: 1s - loss: 1.5769 - accuracy: 0.3760 711/1050 [===================>..........] - ETA: 1s - loss: 1.5769 - accuracy: 0.3762 721/1050 [===================>..........] - ETA: 1s - loss: 1.5768 - accuracy: 0.3766 731/1050 [===================>..........] - ETA: 1s - loss: 1.5779 - accuracy: 0.3757 741/1050 [====================>.........] - ETA: 1s - loss: 1.5782 - accuracy: 0.3755 751/1050 [====================>.........] - ETA: 1s - loss: 1.5771 - accuracy: 0.3761 761/1050 [====================>.........] - ETA: 1s - loss: 1.5773 - accuracy: 0.3759 771/1050 [=====================>........] - ETA: 1s - loss: 1.5786 - accuracy: 0.3751 781/1050 [=====================>........] - ETA: 1s - loss: 1.5789 - accuracy: 0.3750 791/1050 [=====================>........] - ETA: 1s - loss: 1.5794 - accuracy: 0.3748 801/1050 [=====================>........] - ETA: 1s - loss: 1.5794 - accuracy: 0.3750 811/1050 [======================>.......] - ETA: 1s - loss: 1.5798 - accuracy: 0.3751 821/1050 [======================>.......] - ETA: 1s - loss: 1.5807 - accuracy: 0.3753 831/1050 [======================>.......] - ETA: 1s - loss: 1.5810 - accuracy: 0.3754 841/1050 [=======================>......] - ETA: 1s - loss: 1.5812 - accuracy: 0.3754 852/1050 [=======================>......] - ETA: 1s - loss: 1.5810 - accuracy: 0.3757 862/1050 [=======================>......] - ETA: 0s - loss: 1.5808 - accuracy: 0.3756 872/1050 [=======================>......] - ETA: 0s - loss: 1.5826 - accuracy: 0.3752 882/1050 [========================>.....] - ETA: 0s - loss: 1.5819 - accuracy: 0.3754 892/1050 [========================>.....] - ETA: 0s - loss: 1.5823 - accuracy: 0.3754 902/1050 [========================>.....] - ETA: 0s - loss: 1.5825 - accuracy: 0.3751 912/1050 [=========================>....] - ETA: 0s - loss: 1.5832 - accuracy: 0.3750 922/1050 [=========================>....] - ETA: 0s - loss: 1.5836 - accuracy: 0.3747 932/1050 [=========================>....] - ETA: 0s - loss: 1.5835 - accuracy: 0.3745 942/1050 [=========================>....] - ETA: 0s - loss: 1.5832 - accuracy: 0.3744 951/1050 [==========================>...] - ETA: 0s - loss: 1.5828 - accuracy: 0.3747 961/1050 [==========================>...] - ETA: 0s - loss: 1.5825 - accuracy: 0.3746 971/1050 [==========================>...] - ETA: 0s - loss: 1.5833 - accuracy: 0.3743 981/1050 [===========================>..] - ETA: 0s - loss: 1.5827 - accuracy: 0.3744 991/1050 [===========================>..] - ETA: 0s - loss: 1.5829 - accuracy: 0.37411001/1050 [===========================>..] - ETA: 0s - loss: 1.5828 - accuracy: 0.37401011/1050 [===========================>..] - ETA: 0s - loss: 1.5828 - accuracy: 0.37391021/1050 [============================>.] - ETA: 0s - loss: 1.5826 - accuracy: 0.37411031/1050 [============================>.] - ETA: 0s - loss: 1.5825 - accuracy: 0.37401041/1050 [============================>.] - ETA: 0s - loss: 1.5830 - accuracy: 0.37411050/1050 [==============================] - 6s 5ms/step - loss: 1.5831 - accuracy: 0.3739
end of evaluation
 
score:  [1.5830845832824707, 0.37392857670783997]
job end at Wed Feb 28 11:29:55 CET 2024
