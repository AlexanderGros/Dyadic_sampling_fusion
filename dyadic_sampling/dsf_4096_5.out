  1) releases/2021b
job start at Mon Feb 26 22:39:10 CET 2024
2024-02-26 22:39:20.611488: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-26 22:39:20.612462: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.
2024-02-26 22:39:21.314363: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-26 22:39:21.314804: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2600000000 Hz
 
first y shape:  (112000, 8)
datagenerator definition successfull
start AI architecture definition
Model: "model"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input1 (InputLayer)             [(None, 2, 4096, 1)] 0                                            
__________________________________________________________________________________________________
input2 (InputLayer)             [(None, 2, 2048, 1)] 0                                            
__________________________________________________________________________________________________
input3 (InputLayer)             [(None, 2, 1024, 1)] 0                                            
__________________________________________________________________________________________________
input4 (InputLayer)             [(None, 2, 512, 1)]  0                                            
__________________________________________________________________________________________________
input5 (InputLayer)             [(None, 2, 256, 1)]  0                                            
__________________________________________________________________________________________________
input6 (InputLayer)             [(None, 2, 128, 1)]  0                                            
__________________________________________________________________________________________________
conv2d (Conv2D)                 (None, 1, 4089, 40)  680         input1[0][0]                     
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 1, 2041, 40)  680         input2[0][0]                     
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 1, 1017, 40)  680         input3[0][0]                     
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 1, 505, 40)   680         input4[0][0]                     
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 1, 249, 40)   680         input5[0][0]                     
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 1, 121, 30)   510         input6[0][0]                     
__________________________________________________________________________________________________
dropout (Dropout)               (None, 1, 4089, 40)  0           conv2d[0][0]                     
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 1, 2041, 40)  0           conv2d_2[0][0]                   
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 1, 1017, 40)  0           conv2d_4[0][0]                   
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 1, 505, 40)   0           conv2d_6[0][0]                   
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 1, 249, 40)   0           conv2d_8[0][0]                   
__________________________________________________________________________________________________
dropout_10 (Dropout)            (None, 1, 121, 30)   0           conv2d_10[0][0]                  
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 1, 4086, 10)  1610        dropout[0][0]                    
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 1, 2038, 10)  1610        dropout_2[0][0]                  
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 1, 1014, 10)  1610        dropout_4[0][0]                  
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 1, 502, 10)   1610        dropout_6[0][0]                  
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 1, 246, 40)   6440        dropout_8[0][0]                  
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 1, 118, 10)   1210        dropout_10[0][0]                 
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 1, 4086, 10)  0           conv2d_1[0][0]                   
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 1, 2038, 10)  0           conv2d_3[0][0]                   
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 1, 1014, 10)  0           conv2d_5[0][0]                   
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 1, 502, 10)   0           conv2d_7[0][0]                   
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 1, 246, 40)   0           conv2d_9[0][0]                   
__________________________________________________________________________________________________
dropout_11 (Dropout)            (None, 1, 118, 10)   0           conv2d_11[0][0]                  
__________________________________________________________________________________________________
flatten (Flatten)               (None, 40860)        0           dropout_1[0][0]                  
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 20380)        0           dropout_3[0][0]                  
__________________________________________________________________________________________________
flatten_2 (Flatten)             (None, 10140)        0           dropout_5[0][0]                  
__________________________________________________________________________________________________
flatten_3 (Flatten)             (None, 5020)         0           dropout_7[0][0]                  
__________________________________________________________________________________________________
flatten_4 (Flatten)             (None, 9840)         0           dropout_9[0][0]                  
__________________________________________________________________________________________________
flatten_5 (Flatten)             (None, 1180)         0           dropout_11[0][0]                 
__________________________________________________________________________________________________
concatenate (Concatenate)       (None, 87420)        0           flatten[0][0]                    
                                                                 flatten_1[0][0]                  
                                                                 flatten_2[0][0]                  
                                                                 flatten_3[0][0]                  
                                                                 flatten_4[0][0]                  
                                                                 flatten_5[0][0]                  
__________________________________________________________________________________________________
dense1 (Dense)                  (None, 128)          11189888    concatenate[0][0]                
__________________________________________________________________________________________________
dense2 (Dense)                  (None, 8)            1032        dense1[0][0]                     
__________________________________________________________________________________________________
reshape (Reshape)               (None, 8)            0           dense2[0][0]                     
==================================================================================================
Total params: 11,208,920
Trainable params: 11,208,920
Non-trainable params: 0
__________________________________________________________________________________________________
end of architecture
 
Training start
Epoch 1/100
2450/2450 - 1286s - loss: 1.7203 - accuracy: 0.2989 - val_loss: 1.3144 - val_accuracy: 0.4555
2024-02-26 23:00:48.228092: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.

Epoch 00001: val_loss improved from inf to 1.31445, saving model to ./weights_folder/fusion_4096
Epoch 2/100
2450/2450 - 1206s - loss: 1.0646 - accuracy: 0.5378 - val_loss: 1.5466 - val_accuracy: 0.4430

Epoch 00002: val_loss did not improve from 1.31445
Epoch 3/100
2450/2450 - 1202s - loss: 0.7913 - accuracy: 0.6590 - val_loss: 0.8733 - val_accuracy: 0.6420

Epoch 00003: val_loss improved from 1.31445 to 0.87333, saving model to ./weights_folder/fusion_4096
Epoch 4/100
2450/2450 - 1199s - loss: 0.6516 - accuracy: 0.7320 - val_loss: 0.6814 - val_accuracy: 0.7118

Epoch 00004: val_loss improved from 0.87333 to 0.68142, saving model to ./weights_folder/fusion_4096
Epoch 5/100
2450/2450 - 1171s - loss: 0.5281 - accuracy: 0.7894 - val_loss: 0.6498 - val_accuracy: 0.7376

Epoch 00005: val_loss improved from 0.68142 to 0.64980, saving model to ./weights_folder/fusion_4096
Epoch 6/100
2450/2450 - 1170s - loss: 0.4391 - accuracy: 0.8312 - val_loss: 0.5365 - val_accuracy: 0.7841

Epoch 00006: val_loss improved from 0.64980 to 0.53653, saving model to ./weights_folder/fusion_4096
Epoch 7/100
2450/2450 - 1171s - loss: 0.3757 - accuracy: 0.8587 - val_loss: 0.5152 - val_accuracy: 0.7939

Epoch 00007: val_loss improved from 0.53653 to 0.51521, saving model to ./weights_folder/fusion_4096
Epoch 8/100
2450/2450 - 1171s - loss: 0.3172 - accuracy: 0.8833 - val_loss: 0.4424 - val_accuracy: 0.8266

Epoch 00008: val_loss improved from 0.51521 to 0.44243, saving model to ./weights_folder/fusion_4096
Epoch 9/100
2450/2450 - 1172s - loss: 0.2780 - accuracy: 0.8994 - val_loss: 0.4390 - val_accuracy: 0.8316

Epoch 00009: val_loss improved from 0.44243 to 0.43904, saving model to ./weights_folder/fusion_4096
Epoch 10/100
2450/2450 - 1171s - loss: 0.2424 - accuracy: 0.9137 - val_loss: 0.4682 - val_accuracy: 0.8218

Epoch 00010: val_loss did not improve from 0.43904
Epoch 11/100
2450/2450 - 1171s - loss: 0.2166 - accuracy: 0.9225 - val_loss: 0.3922 - val_accuracy: 0.8508

Epoch 00011: val_loss improved from 0.43904 to 0.39221, saving model to ./weights_folder/fusion_4096
Epoch 12/100
2450/2450 - 1171s - loss: 0.1965 - accuracy: 0.9304 - val_loss: 0.4049 - val_accuracy: 0.8548

Epoch 00012: val_loss did not improve from 0.39221
Epoch 13/100
2450/2450 - 1174s - loss: 0.1848 - accuracy: 0.9373 - val_loss: 0.4317 - val_accuracy: 0.8443

Epoch 00013: val_loss did not improve from 0.39221
Epoch 14/100
2450/2450 - 1172s - loss: 0.1684 - accuracy: 0.9422 - val_loss: 0.4378 - val_accuracy: 0.8475

Epoch 00014: val_loss did not improve from 0.39221
Epoch 15/100
2450/2450 - 1171s - loss: 0.1532 - accuracy: 0.9480 - val_loss: 0.3533 - val_accuracy: 0.8724

Epoch 00015: val_loss improved from 0.39221 to 0.35330, saving model to ./weights_folder/fusion_4096
Epoch 16/100
2450/2450 - 1171s - loss: 0.1500 - accuracy: 0.9495 - val_loss: 0.3855 - val_accuracy: 0.8630

Epoch 00016: val_loss did not improve from 0.35330
Epoch 17/100
2450/2450 - 1172s - loss: 0.1430 - accuracy: 0.9520 - val_loss: 0.3316 - val_accuracy: 0.8784

Epoch 00017: val_loss improved from 0.35330 to 0.33158, saving model to ./weights_folder/fusion_4096
Epoch 18/100
2450/2450 - 1171s - loss: 0.1305 - accuracy: 0.9560 - val_loss: 0.4019 - val_accuracy: 0.8589

Epoch 00018: val_loss did not improve from 0.33158
Epoch 19/100
2450/2450 - 1172s - loss: 0.1302 - accuracy: 0.9571 - val_loss: 0.3552 - val_accuracy: 0.8751

Epoch 00019: val_loss did not improve from 0.33158
Epoch 20/100
2450/2450 - 1171s - loss: 0.1140 - accuracy: 0.9611 - val_loss: 0.3687 - val_accuracy: 0.8753

Epoch 00020: val_loss did not improve from 0.33158
Epoch 21/100
2450/2450 - 1172s - loss: 0.1181 - accuracy: 0.9615 - val_loss: 0.3553 - val_accuracy: 0.8790

Epoch 00021: val_loss did not improve from 0.33158
Epoch 22/100
2450/2450 - 1171s - loss: 0.1126 - accuracy: 0.9634 - val_loss: 0.3623 - val_accuracy: 0.8754

Epoch 00022: val_loss did not improve from 0.33158
Epoch 23/100
2450/2450 - 1170s - loss: 0.1035 - accuracy: 0.9665 - val_loss: 0.4091 - val_accuracy: 0.8633

Epoch 00023: val_loss did not improve from 0.33158
Epoch 24/100
2450/2450 - 1172s - loss: 0.1034 - accuracy: 0.9666 - val_loss: 0.4787 - val_accuracy: 0.8425

Epoch 00024: val_loss did not improve from 0.33158
Epoch 25/100
2450/2450 - 1171s - loss: 0.1094 - accuracy: 0.9652 - val_loss: 0.3664 - val_accuracy: 0.8797

Epoch 00025: val_loss did not improve from 0.33158
Epoch 26/100
2450/2450 - 1172s - loss: 0.0993 - accuracy: 0.9688 - val_loss: 0.3399 - val_accuracy: 0.8862

Epoch 00026: val_loss did not improve from 0.33158
Epoch 27/100
2450/2450 - 1172s - loss: 0.0895 - accuracy: 0.9717 - val_loss: 0.4215 - val_accuracy: 0.8608

Epoch 00027: val_loss did not improve from 0.33158
Epoch 00027: early stopping
training time:  31895.44407892227 seconds 
end of training
 
Loading model
end of loading
 
Evaluating model
Traceback (most recent call last):
  File "dyadic_s_fusion.py", line 402, in <module>
    score = model.evaluate(DataGenerator(test_idx, 32, vec_len, shuffle=True), verbose=1)
TypeError: __init__() missing 1 required positional argument: 'vec_len'
job end at Tue Feb 27 07:31:02 CET 2024
